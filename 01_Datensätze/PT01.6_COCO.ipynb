{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f29384-2d74-4beb-b292-d2825da9604a",
   "metadata": {},
   "source": [
    "# COCO - Common Objects in Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2685d4-f49f-4bf4-8254-4bd209cb2da5",
   "metadata": {},
   "source": [
    "Der COCO-Datensatz (Common Objects in Context) ist einer der bekanntesten und am häufigsten verwendeten Datensätze für Computer Vision. Er wird für verschiedene Aufgaben der Bildverarbeitung genutzt, darunter Objekterkennung, Bildsegmentierung, Keypoint Detection und Bildunterschriftengenerierung (Image Captioning).\n",
    "\n",
    "Der COCO-Datensatz ist einer der umfassendsten und anspruchsvollsten Bilddatensätze für Computer Vision. Er deckt mehrere wichtige Aufgaben ab, darunter Objekterkennung, Bildsegmentierung und Pose Estimation. Aufgrund seiner Vielfalt und realistischen Szenen wird er oft als Benchmark für Deep-Learning-Modelle genutzt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178fc27f-9370-4942-bc23-ef7521d0b537",
   "metadata": {},
   "source": [
    "### Hauptmerkmale des COCO-Datensatzes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964c43e1-9b8d-40f3-a686-05d8dcaed562",
   "metadata": {},
   "source": [
    "* Anzahl der Bilder: Über 330.000 Bilder\n",
    "* Anzahl der annotierten Objekte: Mehr als 1,5 Millionen\n",
    "* Anzahl der Klassen: 80 Objektklassen (z. B. Personen, Tiere, Fahrzeuge, Haushaltsgegenstände)\n",
    "* Zusätzliche Annotationen:\n",
    "    * Bounding Boxes (Objekterkennung)\n",
    "    * Segmentierungsmasken (Bildsegmentierung)\n",
    "    * Keypoints (z. B. für menschliche Posen)\n",
    "    * Bildunterschriften für Image Captioning\n",
    "* Realistische Szenen: Enthält Objekte in natürlichen Kontexten, oft mit mehreren überlappenden Objekten pro Bildnd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec91d9eb-a937-4a91-8748-473ca677595e",
   "metadata": {},
   "source": [
    "### Einlesen (und ggf. einmaliger Download) des Datensatzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5576f0cc-21cd-4017-a5b6-b11a8e12e73c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycocotools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycocotools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcoco\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m COCO\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Pfad zur Annotationsdatei\u001b[39;00m\n\u001b[0;32m      4\u001b[0m coco \u001b[38;5;241m=\u001b[39m COCO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannotations/instances_train2017.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pycocotools'"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "# Pfad zur Annotationsdatei\n",
    "coco = COCO(\"annotations/instances_train2017.json\")\n",
    "\n",
    "# Beispiel: Alle Bilder mit der Klasse \"Person\"\n",
    "cat_ids = coco.getCatIds(catNms=['person'])\n",
    "img_ids = coco.getImgIds(catIds=cat_ids)\n",
    "print(f\"Anzahl der Bilder mit Personen: {len(img_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549fca9f-ba3a-4ec1-af90-88f98f9ed176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
