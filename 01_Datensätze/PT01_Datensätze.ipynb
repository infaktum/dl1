{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a0c7e89-1335-40e3-989a-e39bce006813",
   "metadata": {},
   "source": [
    "# Große Datensätze für Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b89616-fde9-4b58-b831-9925ae0c6fe8",
   "metadata": {},
   "source": [
    "Große Datensätze sind ein zentraler Bestandteil der Entwicklung und Verbesserung von Deep-Learning-Modellen, insbesondere für Computer Vision (Bildverarbeitung). Hier sind einige wichtige Gründe, warum große Datensätze entscheidend sind:\n",
    "\n",
    "* __Bessere Generalisierung__: Ein großes und vielfältiges Datenset hilft einem Modell, allgemeine Muster zu lernen, anstatt sich auf spezifische Trainingsdaten zu überanpassen (Overfitting).\n",
    "* ___Ermöglicht tiefere Netzwerke__: Komplexe neuronale Netzwerke mit Millionen von Parametern benötigen viele Beispiele, um effektiv zu lernen und nicht nur zu memorisieren.\n",
    "* __Verbesserte Robustheit__: Große Datensätze mit Variationen in Beleuchtung, Perspektive und Hintergrund machen das Modell robuster gegenüber unbekannten Daten.\n",
    "* __Förderung des Transfer Learning__: Große Datensätze werden oft genutzt, um vorgefertigte Modelle (Pretrained Models) zu trainieren, die dann für andere spezifische Aufgaben weiterverwendet werden können.\n",
    "* __Benchmarking und Vergleichbarkeit__: Standardisierte große Datensätze ermöglichen es Forschern, unterschiedliche Modelle direkt miteinander zu vergleichen, indem sie dieselben Testsets nutzen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f6f68e-30c3-4203-981d-a7708b012b25",
   "metadata": {},
   "source": [
    "## Bekannte Bilddatensätze für Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701f0c45-5b37-4114-84f1-84243172bd1f",
   "metadata": {},
   "source": [
    "#### MNIST (Modified National Institute of Standards and Technology)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4705ee66-0903-468f-89cb-424a3d70de3e",
   "metadata": {},
   "source": [
    "* Typ: Handgeschriebene Ziffern (0-9)\n",
    "* Größe: 70.000 Bilder (60.000 Training, 10.000 Test)\n",
    "* Auflösung: 28×28 Pixel, Graustufen\n",
    "* Verwendung: Einsteiger-Datensatz für Mustererkennung, oft für Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b01c5a8-4957-4f5c-97c7-d5b916f41a28",
   "metadata": {},
   "source": [
    "#### CIFAR-10 (Canadian Institute for Advanced Research)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c951ab7-c16a-430d-8b09-5cf11c335297",
   "metadata": {},
   "source": [
    "* Typ: Farbbilder aus 10 Kategorien (z. B. Autos, Hunde, Flugzeuge)\n",
    "* Größe: 60.000 Bilder (50.000 Training, 10.000 Test)\n",
    "* Auflösung: 32×32 Pixel, RGB\n",
    "* Verwendung: Klassifikation kleiner Objekte, oft für CNN-Experimente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb20c12-6fd2-46d6-b0c6-90eec59ee195",
   "metadata": {},
   "source": [
    "#### CIFAR-100 (Canadian Institute for Advanced Research)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649bf3a3-dbc0-4773-a4e0-bb5078895042",
   "metadata": {},
   "source": [
    "* Typ: Ähnlich wie CIFAR-10, aber mit 100 Klassen\n",
    "* Größe: 60.000 Bilder\n",
    "* Auflösung: 32×32 Pixel, RGB\n",
    "* Verwendung: Komplexere Klassifikationsaufgaben"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cbe015-244e-45dd-b994-9d33febeb9e3",
   "metadata": {},
   "source": [
    "#### ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd2b5f1-a098-4241-9f20-cd561515d2ad",
   "metadata": {},
   "source": [
    "* Typ: Hochauflösende Bilder aus 1.000 Klassen\n",
    "* Größe: Über 14 Millionen Bilder\n",
    "* Auflösung: Unterschiedlich, meist hochauflösend\n",
    "* Verwendung: Wichtigster Benchmark für Deep Learning in der Bildverarbeitung, Grundlage für viele Pretrained-Modelle (z. B. ResNet, VGG, EfficientNet)\n",
    "* Link: [ImageNet](https://www.image-net.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ce460a-b47b-43ef-901c-b66915ce0ae4",
   "metadata": {},
   "source": [
    "#### COCO (Common Objects in Context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7f7dc2-212f-4459-9c99-996ff12335c9",
   "metadata": {},
   "source": [
    "* Typ: Bilder mit mehreren Objekten in realen Szenarien\n",
    "* Größe: 330.000 Bilder mit über 1,5 Millionen annotierten Objekten\n",
    "* Auflösung: Unterschiedlich\n",
    "* Verwendung: Objekterkennung, Bildsegmentierung und Bildunterschriftengenerierung\n",
    "* Link: [COCO](https://cocodataset.org/#home)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823f9ac0-dc9c-4f69-816b-a38a9b7799d1",
   "metadata": {},
   "source": [
    "#### Open Images Datase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5898b09b-1cf4-4d0a-832b-e10a04a19cfc",
   "metadata": {},
   "source": [
    "* Typ: Bilder mit mehreren Objekten und detaillierten Annotationen\n",
    "* Größe: 9 Millionen Bilder\n",
    "* Auflösung: Hochauflösend\n",
    "* Verwendung: Objekterkennung, Bildbeschreibung und Kontextanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4112852-8bb0-4d1e-b1a2-d6cc9c2c3870",
   "metadata": {},
   "source": [
    "#### Pascal VOC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb41c969-7e0f-4184-84f0-9abcfe359d4a",
   "metadata": {},
   "source": [
    "* Typ: Bilder mit Objekten in 20 Kategorien\n",
    "* Größe: Ca. 11.000 Bilder\n",
    "* Auflösung: Unterschiedlich\n",
    "* Verwendung: Benchmark für Objekterkennung und Segmentierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38305d4-5a89-4a64-a15c-6fba156cfb3a",
   "metadata": {},
   "source": [
    "#### LFW (Labeled Faces in the Wild)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a1db5-3590-4c9b-9408-d0a579a5adbc",
   "metadata": {},
   "source": [
    "* Typ: Gesichtserkennungs-Datensatz\n",
    "* Größe: 13.000 Bilder\n",
    "* Auflösung: Unterschiedlich\n",
    "* Verwendung: Gesichtserkennung und Verifikation\n",
    "* Links: [LFW - Kaggle](https://www.kaggle.com/datasets/jessicali9530/lfw-dataset) und [LFW - Scikit-learn](https://scikit-learn.org/0.19/datasets/labeled_faces.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a400aedc-6c2e-487f-95a2-5b458a2b6c9f",
   "metadata": {},
   "source": [
    "#### CelebA (Celeb Faces Attributes Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ca7207-523b-467f-9349-ec0a7d00e19b",
   "metadata": {},
   "source": [
    "* Typ: Prominenten-Gesichter mit Attribut-Labels (z. B. Brille, Bart, Lächeln)\n",
    "* Größe: 200.000 Bilder\n",
    "* Verwendung: Gesichtserkennung und Style-Transfer\n",
    "* Link: [CelebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e103556c-5fd7-4c2f-8369-c68eeaca81cf",
   "metadata": {},
   "source": [
    "### Zusammenfassung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8284e4b-5096-4ceb-a9e8-d8252aef1f27",
   "metadata": {},
   "source": [
    "Große Bilddatensätze sind essenziell für das Training leistungsfähiger Deep-Learning-Modelle. Während MNIST und CIFAR-10 für kleine Experimente genutzt werden, dienen ImageNet und COCO als Basis für hochentwickelte neuronale Netzwerke. In spezialisierten Bereichen wie Gesichtserkennung oder Objekterkennung sind Datensätze wie CelebA oder Pascal VOC entscheidend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de79ac3-7447-40be-bbbb-3afe1e935a9a",
   "metadata": {},
   "source": [
    "### Links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdabe4d-bb2c-4369-8af9-8b39ae2b6d6e",
   "metadata": {},
   "source": [
    "\n",
    "* [WordNet](https://wordnet.princeton.edu/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4635358f-5b1e-4d78-89f2-1d02f6b4d5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
