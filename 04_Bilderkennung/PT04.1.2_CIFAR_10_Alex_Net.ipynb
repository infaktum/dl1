{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f29384-2d74-4beb-b292-d2825da9604a",
   "metadata": {},
   "source": [
    "# AlexNet auf Datensatz CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797999fd-8d0a-4f2d-9853-d65db4c55a1c",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a899e2ca-43d1-412a-a40d-5c74b01ef9ad",
   "metadata": {},
   "source": [
    "__AlexNet__ wurde 2012 von __Alex Krizhevsky__, __Ilya Sutskever__ und __Geoffrey Hinton__ entwickelt entwickelt und war ein damals bahnbrechendes tiefes neuronales Netzwerk. Es revolutionierte das Gebiet des Deep Learning, insbesondere im Bereich der Bildverarbeitung, und gewann den ImageNet Large Scale Visual Recognition Challenge (ILSVRC) Wettbewerb 2012 mit einer beeindruckenden Fehlerrate von nur 15,3 %, während der zweitplatzierte Algorithmus eine Fehlerrate von etwa 26 % hatte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e545001-91e8-4fac-bf88-02c5c25687e7",
   "metadata": {},
   "source": [
    "### Laden des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bfd1c1-4e0f-4647-b910-527d4830083b",
   "metadata": {},
   "source": [
    "Mit Hilfe von PyTorch können wir das trainierte AlexNet direkt laden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5ddd83c-2d8d-4acd-96da-7ef0b2fbb890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\ki\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\ki\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.alexnet(pretrained = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459faf21-4db2-4742-8940-cf4f83d689b4",
   "metadata": {},
   "source": [
    "## Die Architektur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d9da7c-0667-42ee-9df6-e315ab40847f",
   "metadata": {},
   "source": [
    "AlexNet setzt mehrere Schichten von Convolutional Networks zur Vorverarbeitung der Bilddaten ein, und danach drei Schichten vollständig verbundener Netzwerke:\n",
    "\n",
    "* Fünf __Convolutional Layers__ (Conv)\n",
    "* Drei __Fully Connected Layers__ (FC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3146fc-7c6e-42af-b0e9-15b2429e8e57",
   "metadata": {},
   "source": [
    "#### Zentrale Merkmale von AlexNet\n",
    "\n",
    "* __ReLU-Aktivierung__: Statt der damals üblichen Sigmoid- oder Tanh-Funktionen verwendete AlexNet die ReLU-Funktion (Rectified Linear Unit), was das Training deutlich beschleunigte.\n",
    "* __Dropout__: Um Overfitting zu vermeiden, wurde erstmals das Dropout-Verfahren eingeführt.\n",
    "* __Data Augmentation__: Techniken wie Spiegelung und Verschiebung von Bildern verbesserten die Generalisierung.\n",
    "* __GPU-Nutzung__: Das Netzwerk wurde auf zwei GPUs parallel trainiert, was eine effizientere Berechnung ermöglichte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "042294c4-db67-4357-b9cb-3e9a67a56c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08356ad4-db0f-4cab-a418-96fe667f5d76",
   "metadata": {},
   "source": [
    "Wir verschieben das Modell in die GPU, falls vorhanden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a28c5fc4-3cb4-45f6-bdb3-c49a8037563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f1be58-91ea-48e0-accc-385f6edb88e7",
   "metadata": {},
   "source": [
    "### Laden des CIFAR-10-Datensatzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "271b614f-ed56-4730-bb50-a221a226cb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd65c4b0-fd7d-4608-b6fa-bc8ab4fbf8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './data'\n",
    "\n",
    "batch_size = 10000\n",
    "test_data = datasets.CIFAR10(root=root,train=False,download=True,transform=ToTensor())\n",
    "data, targets, classes = test_data.data, test_data.targets, test_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa4172a-c732-4189-899a-76e1ffe034a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frog\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nr = 4\n",
    "image, target = data[nr], classes[targets[nr]]\n",
    "\n",
    "print(target)\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e310f66-f0ca-43ae-8687-5d2dfe4d1eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(image.shape)\n",
    "pixels = 32\n",
    "r, g, b = image[0], image[1], image[2]\n",
    "rgb = np.stack([r, g, b], axis=-1)\n",
    "image2 = Image.fromarray(rgb, 'RGB')\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "input_tensor = preprocess(image2)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "input_batch = input_batch.to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "probabilities = F.softmax(output[0], dim=0)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "with open('imagenet_classes.txt','r') as f:\n",
    "    categories = [line.strip()  for line in f]\n",
    "    \n",
    "\n",
    "label = np.argmax(probabilities.to('cpu')).item()\n",
    "\n",
    "print(categories[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdbc9d4-084a-4203-a4d9-712fff9ddf79",
   "metadata": {},
   "source": [
    "### Anmerkungen\n",
    "\n",
    "[^1]: Ilya Sutskever ist einer der Gründer von __OpenAI__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2763b6-eabd-4208-8191-eae1e5df0ef1",
   "metadata": {},
   "source": [
    "### Links\n",
    "\n",
    "https://pytorch.org/hub/pytorch_vision_alexnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2c1d9-537e-4fd4-85c2-dac16d4dacf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
