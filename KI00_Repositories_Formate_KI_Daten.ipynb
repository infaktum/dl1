{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "189c48fd-4114-413a-acd3-635905b3e605",
   "metadata": {},
   "source": [
    "# Repositories für freie Daten für die KI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e49bdd-6b8a-48a4-bc27-59bef2a341bc",
   "metadata": {},
   "source": [
    "## Formate\n",
    "\n",
    "* kagglehub \n",
    "* yolo\n",
    "* huggingfaces\n",
    "* Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b29714-b9bd-4c29-88f4-00b78f8b34e0",
   "metadata": {},
   "source": [
    "## Kagglehub\n",
    "\n",
    "Installation mit\n",
    "\n",
    "\n",
    "```python\n",
    "pip install kagglehub\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d0327f-58ca-499c-a15f-a8d5dbe5d150",
   "metadata": {},
   "source": [
    "### YOLO - You Only Look Once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7e194a-c3b7-4891-9472-2fb40e2b7382",
   "metadata": {},
   "source": [
    "Das YOLO-Format (You Only Look Once) für Datensätze ist ein spezifisches Format, das für die Objekt- und Bildklassifizierung in der Computer Vision verwendet wird. Es besteht aus zwei Hauptkomponenten:\n",
    "\n",
    "1. **Bilddatei**: Die Bilder, die analysiert werden sollen, werden in einem Ordner gespeichert.\n",
    "\n",
    "2. **Label-Datei**: Für jedes Bild gibt es eine entsprechende Textdatei mit der gleichen Basisdatei, die die Objekte im Bild beschreibt. Jede Zeile in dieser Datei enthält:\n",
    "- Die Klassen-ID (eine Zahl, die der Klasse des Objekts entspricht)\n",
    "- Die x-Koordinate des Mittelpunkts des Objekts (relativ zur Bildbreite)\n",
    "- Die y-Koordinate des Mittelpunkts des Objekts (relativ zur Bildhöhe)\n",
    "- Die Breite des Objekts (relativ zur Bildbreite)\n",
    "- Die Höhe des Objekts (relativ zur Bildhöhe)\n",
    "\n",
    "Die Werte sind normalisiert, was bedeutet, dass sie zwischen 0 und 1 liegen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc424826-610a-40f5-ab76-bbaf069a0270",
   "metadata": {},
   "source": [
    "https://docs.ultralytics.com/de/datasets/detect/#coco-dataset-format-to-yolo-format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c9a884-b824-482a-967d-4a43e6674e08",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/You_Only_Look_Once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4dfb33-e519-4269-9c2c-b2112e664e6d",
   "metadata": {},
   "source": [
    "## Repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb4a591-1b85-4136-96f1-7c37d3333d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7df05bdb-9e00-472e-a41b-5450e05d3d89",
   "metadata": {},
   "source": [
    "### Kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde1e3d-e135-4430-8818-1ae28294bd75",
   "metadata": {},
   "source": [
    "[Kagglehub auf github](https://github.com/Kaggle/kagglehub/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf55c89-94b3-4d2c-95a2-41447eeca188",
   "metadata": {},
   "source": [
    "## Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bf9d7c-c0e3-476f-95e8-7ed371f5466c",
   "metadata": {},
   "source": [
    "[Hugging Face](https://huggingface.co/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118c2e57-ca1f-4f0b-b87d-6eff88fa6b39",
   "metadata": {},
   "source": [
    "### Ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab98bafd-3596-49be-8466-817cf2cb941f",
   "metadata": {},
   "source": [
    "https://docs.ultralytics.com/de/datasets/detect/african-wildlife/\n",
    "\n",
    "https://github.com/ultralytics/assets/releases/download/v0.0.0/african-wildlife.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f9ffd9-00e5-4fe1-9e57-3cc85f8a3f1b",
   "metadata": {},
   "source": [
    "## Bekannte Datensätze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a61221-922e-48c9-9705-53af84ea0dd2",
   "metadata": {},
   "source": [
    "### CIFAR\n",
    "\n",
    "Der CIFAR-10-Datensatz (Canadian Institute For Advanced Research) ist eine Sammlung von Bildern, die häufig für Algorithmen des maschinellen Lernens und des Computersehens verwendet wird. Er wurde von Forschern des CIFAR-Instituts entwickelt und besteht aus 60.000 32x32-Farbbildern in 10 verschiedenen Klassen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92097faf-54cb-4301-ade1-b93ad3b4b96b",
   "metadata": {},
   "source": [
    "#### CIFAR-10\n",
    "\n",
    "Der CIFAR-10-Datensatz (Canadian Institute For Advanced Research) ist eine Sammlung von Bildern, die häufig für Algorithmen des maschinellen Lernens und des Computersehens verwendet wird. Er wurde von Forschern des CIFAR-Instituts entwickelt und besteht aus 60.000 32x32-Farbbildern in 10 verschiedenen Klassen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e108fa-8664-4a67-b9a2-fb0c6bd3fe08",
   "metadata": {},
   "source": [
    "#### CIFAR-100\n",
    "Der CIFAR-100-Datensatz (Canadian Institute For Advanced Research) ist eine bedeutende Erweiterung des CIFAR-10-Datensatzes, der aus 60.000 32x32-Farbbildern in 100 verschiedenen Klassen besteht. Er wurde von Forschern des CIFAR-Instituts entwickelt und bietet einen anspruchsvolleren Datensatz für komplexere Aufgaben in den Bereichen maschinelles Lernen und Computer Vision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5307d100-3818-4922-9c10-8cfe36ad10a6",
   "metadata": {},
   "source": [
    "### Fashion-MNIST\n",
    "Der Fashion-MNIST-Datensatz ist eine Datenbank mit Artikelbildern von Zalando, die aus einem Trainingssatz von 60.000 Beispielen und einem Testsatz von 10.000 Beispielen besteht. Jedes Beispiel ist ein 28x28-Graustufenbild, das mit einem Label aus 10 Klassen verknüpft ist. Fashion-MNIST soll als direkter Ersatz für den ursprünglichen MNIST-Datensatz zum Benchmarking von Algorithmen für maschinelles Lernen dienen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ca4eb3-6e22-438a-b1a3-7ab0ed85c62c",
   "metadata": {},
   "source": [
    "### ImageNet\n",
    "\n",
    "ImageNet ist eine umfangreiche Datenbank mit beschrifteten Bildern, die für die Forschung zur visuellen Objekterkennung entwickelt wurde. Sie enthält über 14 Millionen Bilder, wobei jedes Bild mit WordNet-Synsets annotiert ist. Damit ist sie eine der umfangreichsten Ressourcen, die für das Training von Deep-Learning-Modellen für Computer-Vision-Aufgaben zur Verfügung stehen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986c61cb-3559-4873-a9f3-a6b90ee45aeb",
   "metadata": {},
   "source": [
    "#### ImageNet-10\n",
    "Der ImageNet10-Datensatz ist eine kleine Teilmenge der ImageNet-Datenbank, entwickelt von Ultralytics entwickelt wurde und für CI-Tests, Plausibilitätsprüfungen und schnelle Tests von Trainingspipelines gedacht ist. Dieser Datensatz besteht aus dem ersten Bild im Trainingssatz und dem ersten Bild aus dem Validierungssatz der ersten 10 Klassen in ImageNet. Obwohl er deutlich kleiner ist, behält er die Struktur und Vielfalt des ursprünglichen ImageNet-Datensatzes bei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0f3e4d-d02c-456e-ae04-51af4f58870d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
