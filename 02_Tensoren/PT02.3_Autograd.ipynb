{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6a67a70-e6d8-4d16-8529-45ef9ccb3597",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cc7e0a-dd9f-4ad0-92d1-7159ac77bfac",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823e2205-b86c-4640-ab8b-8bd235050216",
   "metadata": {},
   "source": [
    "__Backpropagation__ (kurz für _Backward Propagation of Errors_) ist der essentielle Algorithmus für das Training künstlicher neuronaler Netze (KNNs). Er ermöglicht es dem Netzwerk, aus Fehlern zu lernen und seine Gewichtungen anzupassen. Besonders beim __Deep Learning__ ist Backpropagation entscheidend, um tiefe neuronale Netzwerke zu trainieren. Ohne Backpropagation wäre das Trainieren komplexer Modelle mit vielen Schichten nicht möglich."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecd4cce-bb33-40d6-802a-4508789e8bb3",
   "metadata": {},
   "source": [
    "### Der Gradientenabstieg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebabfca-9fd4-47b7-949a-117818e93da6",
   "metadata": {},
   "source": [
    "Bei der Anpassung der Gewichte wird der __Gradientenabstieg__ (_gradient descent_) verwendet, um eine vorgegebene __Verlustfunktion__ (_loss function_) zu minimieren. Dazu muss für die Gewichte jeweils der __Gradient__ berechnet werden - ein aufwändiges Rechenverfahren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021cf7ac-ba27-4884-bd3a-5502bce00b44",
   "metadata": {},
   "source": [
    "## Autograd - Automatisierte Berechnung des Gradienten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be804df-4f2d-4082-8ca4-f3ad3a4a64d3",
   "metadata": {},
   "source": [
    "Die `Tensoren` in `PyTorch` können den Gradienten unter Transformationen, wie sie in Neuronalen Netzwerken durchgeführt werden, automatisiert berechnen. \n",
    "\n",
    "Da die Berechnung des Gradienten Rechenzeit und Arbeitsspeicher verwendet, ist dieses Feature bei der Erzeugung von Tensoren standardmäßig ausgeschaltet. Es muss bei Bedarf bei der Erzeugung des Tensors expliziert eingeschaltet werden:\n",
    "\n",
    "```python \n",
    "t = toch.tensor([1,2,3],requires_grad = True)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99337ce-baa3-40a1-bd9f-3d975e1ed85b",
   "metadata": {},
   "source": [
    "### Ein Beispiel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc89a42-c681-466d-8dc0-0ab7e795876c",
   "metadata": {},
   "source": [
    "Als Beispielfunktion  $F$ nehmen wir die Quadratsumme der Elemente eines Vektors $v = (x_1, \\cdots, x_N)$:\n",
    "\n",
    "$$F(v) = \\sum x_k^2.$$\n",
    "\n",
    "Der Gradient dieser Funktion für einen Vektor  ist:\n",
    "\n",
    "$$ \\text{grad} \\;F (v)= (2x_1,\\cdots,2x_N) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf668db7-262c-4e77-bc1b-af03edf594b1",
   "metadata": {},
   "source": [
    "Wir erstellen einen Vektor und setzen `required_grad` auf `true`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "301afe77-ebe7-4739-b16a-c3edf75be891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "v = torch.tensor([1,2,3], dtype = torch.float, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "639207cf-e0da-4f52-9b8f-9c0492031d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = v.pow(2).sum()\n",
    "F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9669eff9-e78f-4dda-b90f-ddc483b055f1",
   "metadata": {},
   "source": [
    "Nun berechnen wir den Gradienten von $F$ an der Stelle $x$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c663dc-220a-424d-a402-f9cf242849d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4., 6.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.backward()\n",
    "v.grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722a5782-e100-4946-81e1-be79fa252da3",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
